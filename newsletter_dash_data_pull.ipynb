{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import looker_sdk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from textwrap import wrap\n",
    "from datetime import date\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All environment variables set.\n",
      "Looker SDK 3.1 initialized successfully.\n",
      "Cristian\n",
      "Cristian\n"
     ]
    }
   ],
   "source": [
    "# Base URL for API. Do not include /api/* in the url\n",
    "base_url = \"https://looker.clarityhs.com:19999\"\n",
    "\n",
    "#Access login info from .ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/Users/cristiandeleon/RTFH_DataDashboard/env/.ini')\n",
    "\n",
    "# API 3 client id\n",
    "client_id = str(config['login']['client_id'])# Enter your client_id here\n",
    "# API 3 client secret\n",
    "client_secret = str(config['login']['client_secret']) # Enter your client_secret here\n",
    "\n",
    "# Set to false if testing locally against self-signed certs. Otherwise leave True\n",
    "verify_ssl=True\n",
    "\n",
    "os.environ[\"LOOKERSDK_BASE_URL\"] = base_url #If your looker URL has .cloud in it (hosted on GCP), do not include :19999 (ie: https://your.cloud.looker.com).\n",
    "os.environ[\"LOOKERSDK_API_VERSION\"] = \"3.1\" #3.1 is the default version. You can change this to 4.0 if you want.\n",
    "os.environ[\"LOOKERSDK_VERIFY_SSL\"] = \"true\" #Defaults to true if not set. SSL verification should generally be on unless you have a real good reason not to use it. Valid options: true, y, t, yes, 1.\n",
    "os.environ[\"LOOKERSDK_TIMEOUT\"] = \"120\" #Seconds till request timeout. Standard default is 120.\n",
    "\n",
    "#Get the following values from your Users page in the Admin panel of your Looker instance > Users > Your user > Edit API keys. If you know your user id, you can visit https://your.looker.com/admin/users/<your_user_id>/edit.\n",
    "os.environ[\"LOOKERSDK_CLIENT_ID\"] =  client_id #No defaults.\n",
    "os.environ[\"LOOKERSDK_CLIENT_SECRET\"] = client_secret #No defaults. This should be protected at all costs. Please do not leave it sitting here, even if you don't share this document.\n",
    "\n",
    "print(\"All environment variables set.\")\n",
    "\n",
    "sdk = looker_sdk.init31()\n",
    "print('Looker SDK 3.1 initialized successfully.')\n",
    "\n",
    "my_user = sdk.me()\n",
    "\n",
    "#Output is an instance of the User model, but can also be read like a python dict. This applies to all Looker API calls that return Models.\n",
    "#Example: The following commands return identical output. Feel free to use whichever style is more comfortable for you.\n",
    "\n",
    "print(my_user.first_name) #Model dot notation\n",
    "print(my_user[\"first_name\"]) #Dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Look Data for Newsletter Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull look data\n",
    "temp1 = sdk.run_look(look_id=79680, result_format='json', limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform look data into pandas dataframe\n",
    "n_temp = json.loads(temp1)\n",
    "df = pd.DataFrame.from_dict(n_temp)\n",
    "df\n",
    "# Turn date columns into type datetime\n",
    "df['enrollments.start_date'] = pd.to_datetime(df['enrollments.start_date'], errors='coerce')\n",
    "df['enrollments.end_date'] = pd.to_datetime(df['enrollments.end_date'])\n",
    "df['household_move_in_date.move_in_date'] = pd.to_datetime(df['household_move_in_date.move_in_date'])\n",
    "\n",
    "# Convert age column as type int and identify null values using -1\n",
    "df['clients.age'] = df['clients.age'].fillna(-1).astype(int)\n",
    "df = df[~pd.isnull(df['enrollments.start_date'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp4 = sdk.run_look(look_id=79431, result_format='json', limit=200000)\n",
    "n_temp4 = json.loads(temp4)\n",
    "df3 = pd.DataFrame.from_dict(n_temp4)\n",
    "df3['referrals.date_date'] = pd.to_datetime(df3['referrals.date_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'assets/{date.today()}'\n",
    "if not os.path.isdir(PATH):\n",
    "    os.mkdir(PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions utilized in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### Inflow Functions\n",
    "\n",
    "\"\"\"\n",
    "def getActiveClientsDF(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Filter dataframe for only those clients that were active in the specified reporting period.\n",
    "    '''\n",
    "    return df[(df['enrollments.start_date']<rep_period_end) & ((df['enrollments.end_date']>=rep_period_start) | pd.isnull(df['enrollments.end_date']))].reset_index(drop=True).copy()\n",
    "\n",
    "def getActiveClientsCount(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Use get the count of Unique ID's from the dataframe returned by the getActiveClientsDF() function call.\n",
    "    '''\n",
    "    return getActiveClientsDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].nunique()#df[(df['enrollments.start_date']<rep_period_end) & ((df['enrollments.end_date']>=rep_period_start) | pd.isnull(df['enrollments.end_date']))]['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getClientsEnrolledInRepPeriodDF(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns a dataframe filtered for only those clients that have an Enrollment Start Date in the reporting period.\n",
    "    '''\n",
    "    return df[(df['enrollments.start_date']<rep_period_end) & (df['enrollments.start_date']>=rep_period_start)].reset_index(drop=True).copy()\n",
    "\n",
    "def getClientsEnrolledCount(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns the number of Unique ID's in the dataframe returned by the getClientsEnrolledInRepPeriodDF() function call. \n",
    "    '''\n",
    "    return getClientsEnrolledInRepPeriodDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getClientsEnrolledSet(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns the set of Unique ID's in the dataframe returned by the getClientsEnrolledInRepPeriodDF() function call. \n",
    "    '''\n",
    "    return set(getClientsEnrolledInRepPeriodDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].unique())\n",
    "\n",
    "def getClientsActiveForEntireRepPeriodSet(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns the set of Unique ID's for clients that were served every day in the reporting period.\n",
    "    '''\n",
    "    return set(df[(df['enrollments.start_date']<rep_period_start) & ((df['enrollments.end_date']>=rep_period_end) | pd.isnull(df['enrollments.end_date']))]['clients.unique_identifier'].unique())\n",
    "\n",
    "def getFirstTimeHomelessDF(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns a dataframe of each clients first enrollment by start date and then filters for \n",
    "    clients who's first enrollment was in the reporting period.\n",
    "    '''\n",
    "    idx = df.groupby('clients.unique_identifier')['enrollments.start_date'].idxmin()\n",
    "    df = df.loc[idx].reset_index(drop=True)\n",
    "    return df[(df['enrollments.start_date']<rep_period_end) & (df['enrollments.start_date']>=rep_period_start)].reset_index(drop=True).copy()\n",
    "\n",
    "def getFirstTimeHomelessCount(df, rep_period_start, rep_period_end):\n",
    "    '''\n",
    "    Returns the number of unique ID's returned by the getFirstTimeHomelessDF() function call.\n",
    "    '''\n",
    "    return getFirstTimeHomelessDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].nunique()\n",
    "\"\"\"\n",
    "### Outflow Functions\n",
    "\n",
    "\"\"\"\n",
    "def getClientsExitedInReportingPeriodDF(df, rep_period_start, rep_period_end):\n",
    "     return df[(df['enrollments.end_date']>=rep_period_start) & (df['enrollments.end_date']<rep_period_end) & ~pd.isnull(df['enrollments.end_date'])].reset_index(drop=True).copy()\n",
    "\n",
    "def getClientsExitedInReportingPeriodSet(df, rep_period_start, rep_period_end):\n",
    "    return set(getClientsExitedInReportingPeriodDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].unique())\n",
    "\n",
    "def getClientsExitedAndHoused(df, rep_period_start, rep_period_end):\n",
    "    temp_df = getClientsExitedInReportingPeriodDF(df, rep_period_start, rep_period_end)\n",
    "    return temp_df[temp_df['last_screen.housed_on_exit']=='Housed'].reset_index(drop=True)\n",
    "\n",
    "def getExitToMoveInDF(df, rep_period_start, rep_period_end):\n",
    "    exit_to_or_move_in_enroll_set = set(\n",
    "                                        list(getClientsExitedAndHoused(df, rep_period_start, rep_period_end)['enrollments.id'].unique()) + \n",
    "                                        list(getClientsWithMoveInDF(df, rep_period_start, rep_period_end)['enrollments.id'].unique())\n",
    "                                    )\n",
    "    return df[df['enrollments.id'].isin(exit_to_or_move_in_enroll_set)].reset_index(drop=True)\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "### Housing Move-In Functions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def getClientsWithMoveInDF(df, rep_period_start, rep_period_end):\n",
    "    return df[~pd.isnull(df['household_move_in_date.move_in_date']) & (df['household_move_in_date.move_in_date']>=rep_period_start) & (df['household_move_in_date.move_in_date']<rep_period_end)].reset_index(drop=True)\n",
    "\n",
    "def getSetOfClientsWithMoveIn(df, rep_period_start, rep_period_end):\n",
    "    return set(getClientsWithMoveInDF(df, rep_period_start, rep_period_end)['clients.unique_identifier'].unique())\n",
    "\n",
    "def getCountOfClientsWithMoveIn(df, rep_period_start, rep_period_end):\n",
    "    return len(getSetOfClientsWithMoveIn(df, rep_period_start, rep_period_end))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### Subpopulation Count Functions\n",
    "\n",
    "\"\"\"\n",
    "def getSeniorsServedDF(df):\n",
    "    return df[df['clients.age']>=55].reset_index(drop=True)\n",
    "\n",
    "def getSeniorsServedCount(df):\n",
    "    return df[df['clients.age']>=55]['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getTAYServedCount(df):\n",
    "    return df[(df['clients.age']>=18) & (df['clients.age']<=24)]['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getTAYServedDF(df):\n",
    "    return df[(df['clients.age']>=18) & (df['clients.age']<=24)].reset_index(drop=True)\n",
    "\n",
    "def getVeteransServedCount(df):\n",
    "    return df[df['static_demographics.veteran_text']==\"Yes\"]['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getVeteransServedDF(df):\n",
    "    return df[df['static_demographics.veteran_text']==\"Yes\"].reset_index(drop=True)\n",
    "\n",
    "def getFamiliesServedCount(df):\n",
    "    return df[(df['household_makeup.household_type']==\"Household with Children\") & (df['entry_screen.head_of_household']=='Yes')]['clients.unique_identifier'].nunique()\n",
    "\n",
    "def getFamiliesServedDF(df):\n",
    "    return df[(df['household_makeup.household_type']==\"Household with Children\") & (df['entry_screen.head_of_household']=='Yes')].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race Data Pull for New To System, Active and Housed Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.copy()\n",
    "\n",
    "monthly_time_periods_d = {\n",
    "    \"Monthly\": 1,\n",
    "    \"Quarterly\": 4,\n",
    "    \"6 - Month\": 6,\n",
    "    \"Annual\": 12\n",
    "} \n",
    "\n",
    "list_of_dfs_2 = []\n",
    "\n",
    "REPORT_START_DATE = pd.to_datetime('2022-09-01')\n",
    "while REPORT_START_DATE<pd.to_datetime(date.today().strftime(\"%Y-%m-01\")):\n",
    "    for time_range in monthly_time_periods_d:\n",
    "        if time_range==\"Monthly\":\n",
    "            \n",
    "            # Set repording period start and end\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=1)\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=1)\n",
    "            lookback_end = rep_period_start\n",
    "    \n",
    "        else:\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE) - relativedelta(months=monthly_time_periods_d[time_range]-1)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=monthly_time_periods_d[time_range])\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=monthly_time_periods_d[time_range])\n",
    "            lookback_end = rep_period_start\n",
    "        \n",
    "        # Section 1 New to System Metrics by Race\n",
    "        section1_df = pd.concat([\n",
    "            pd.DataFrame(getFirstTimeHomelessDF(temp, rep_period_start, rep_period_end).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"FTH Count by Race\"}).T, \n",
    "            pd.DataFrame(getClientsExitedAndHoused(temp, rep_period_start, rep_period_end).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Housed Count by Race\"}).T, \n",
    "            pd.DataFrame(getClientsEnrolledInRepPeriodDF(temp, rep_period_start, rep_period_end).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"New Program Entries Count by Race\"}).T,\n",
    "            pd.DataFrame(df3[(df3['referrals.date_date']>=rep_period_start) & (df3['referrals.date_date']<rep_period_end)].groupby(['static_demographics.race_text'])['client.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"client.unique_identifier\": \"New Referrals Count by Race\"}).T,\n",
    "            ]).T\n",
    "\n",
    "        # Section 2 Active Metrics by Race\n",
    "        section2_df = pd.concat([\n",
    "            pd.DataFrame(getActiveClientsDF(temp, rep_period_start, rep_period_end).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active Count by Race\"}).T, \n",
    "            pd.DataFrame(getSeniorsServedDF(getActiveClientsDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active Seniors Count by Race\"}).T, \n",
    "            pd.DataFrame(getTAYServedDF(getActiveClientsDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active TAY Count by Race\"}).T, \n",
    "            pd.DataFrame(getVeteransServedDF(getActiveClientsDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active Veterans Count by Race\"}).T, \n",
    "            pd.DataFrame(getFamiliesServedDF(getActiveClientsDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active Families Count by Race\"}).T\n",
    "            ]).T\n",
    "        \n",
    "\n",
    "        # Section 3 Housed Metrics by Race\n",
    "\n",
    "        section3_df = pd.concat([\n",
    "            pd.DataFrame(getSeniorsServedDF(getExitToMoveInDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Housed Seniors Count by Race\"}).T, \n",
    "            pd.DataFrame(getTAYServedDF(getExitToMoveInDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Housed TAY Count by Race\"}).T,\n",
    "            pd.DataFrame(getVeteransServedDF(getExitToMoveInDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Housed Veterans Count by Race\"}).T,\n",
    "            pd.DataFrame(getFamiliesServedDF(getExitToMoveInDF(temp, rep_period_start, rep_period_end)).groupby(['static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Housed Families Count by Race\"}).T\n",
    "            ]).T\n",
    "\n",
    "        data_merged_by_race_df = pd.merge(pd.merge(section1_df, section2_df, on='static_demographics.race_text', how='outer'), section3_df, on='static_demographics.race_text', how='outer').T\n",
    "        data_merged_by_race_df = data_merged_by_race_df.T.reset_index()\n",
    "\n",
    "        for col in data_merged_by_race_df.columns:\n",
    "            if 'by Race' in col:\n",
    "                data_merged_by_race_df[f'{col} by Percent'] = data_merged_by_race_df[col]/data_merged_by_race_df[col].sum()\n",
    "        data_merged_by_race_df['Reporting Month'] = REPORT_START_DATE.strftime(\"%b-%Y\")\n",
    "        data_merged_by_race_df['Reporting Window'] = time_range\n",
    "\n",
    "        list_of_dfs_2.append(data_merged_by_race_df)\n",
    "\n",
    "    REPORT_START_DATE = REPORT_START_DATE + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat(list_of_dfs_2)\n",
    "df2[[x for x in df2.columns if 'Race' in x]] = df2[[x for x in df2.columns if 'by Race' in x]].fillna(0).astype(int)\n",
    "df2.to_csv(f'{PATH}/newsletter_counts_by_race.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pull for the Active Donut Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev_dict = {\n",
    "    'Safe Haven':'SH', \n",
    "    'Other':'OTH', \n",
    "    'Transitional Housing':'TH',\n",
    "    'Homelessness Prevention':'HP', \n",
    "    'Street Outreach':'OUT', \n",
    "    'Coordinated Entry':'CE',\n",
    "    'Day Shelter':'DS', \n",
    "    'Emergency Shelter':'ES', \n",
    "    'Services Only':'SO',\n",
    "    'Permanent Housing':'PH'\n",
    "}\n",
    "\n",
    "def proj_type_rename(row):\n",
    "    if row['programs.project_type_code'] in ['PH - Housing Only', 'PH - Housing with Services (no disability required for entry)', 'PH - Permanent Supportive Housing (disability required for entry)','PH - Rapid Re-Housing']:\n",
    "        return 'Permanent Housing'\n",
    "    else:\n",
    "        return row['programs.project_type_code']\n",
    "\n",
    "\n",
    "def append_abbrev(row):\n",
    "    return f\"{row['Project Type']} ({abbrev_dict[row['Project Type']]})\"\n",
    "\n",
    "\n",
    "temp = df.copy()\n",
    "\n",
    "monthly_time_periods_d = {\n",
    "    \"Monthly\": 1,\n",
    "    \"Quarterly\": 4,\n",
    "    \"6 - Month\": 6,\n",
    "    \"Annual\": 12\n",
    "} \n",
    "\n",
    "list_of_dfs_3 = []\n",
    "\n",
    "REPORT_START_DATE = pd.to_datetime('2022-09-01')\n",
    "while REPORT_START_DATE<pd.to_datetime(date.today().strftime(\"%Y-%m-01\")):\n",
    "    for time_range in monthly_time_periods_d:\n",
    "        if time_range==\"Monthly\":\n",
    "            \n",
    "            # Set repording period start and end\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=1)\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=1)\n",
    "            lookback_end = rep_period_start\n",
    "    \n",
    "        else:\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE) - relativedelta(months=monthly_time_periods_d[time_range]-1)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=monthly_time_periods_d[time_range])\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=monthly_time_periods_d[time_range])\n",
    "            lookback_end = rep_period_start\n",
    "            \n",
    "        # Filter df for active clients\n",
    "        active_clients_by_proj_type_df = getActiveClientsDF(temp, rep_period_start, rep_period_end)\n",
    "        # Change the Project Type to group PH programs\n",
    "        active_clients_by_proj_type_df['Project Type'] = active_clients_by_proj_type_df.apply(lambda row: proj_type_rename(row), axis=1)\n",
    "        # Summing the client count by their new Project Type grouping\n",
    "        active_clients_by_proj_type_df = active_clients_by_proj_type_df.groupby(['Project Type', 'static_demographics.race_text'])['clients.unique_identifier'].nunique().sort_values()\n",
    "        # Convert groupby object into dataframe\n",
    "        active_clients_by_proj_type_df = pd.DataFrame(active_clients_by_proj_type_df).reset_index()\n",
    "        # Reduce active_clients_by_proj_type_df dataframe to 2 columns\n",
    "        active_clients_by_proj_type_df = active_clients_by_proj_type_df[['Project Type', 'static_demographics.race_text', 'clients.unique_identifier']].copy()\n",
    "        active_clients_by_proj_type_df = pd.merge(active_clients_by_proj_type_df.reset_index(),pd.DataFrame(pd.Series(abbrev_dict)).reset_index().rename(columns={0:'Abbrev', 'index':'Project Type'}), on='Project Type')\n",
    "        active_clients_by_proj_type_df['Project Type'] = active_clients_by_proj_type_df.apply(lambda row: append_abbrev(row), axis=1)\n",
    "        active_clients_by_proj_type_df = active_clients_by_proj_type_df.set_index('Project Type').drop('index', axis=1)\n",
    "        active_clients_by_proj_type_df = active_clients_by_proj_type_df.reset_index()\n",
    "        active_clients_by_proj_type_df['Active Clients Count Percent'] = active_clients_by_proj_type_df['clients.unique_identifier']/active_clients_by_proj_type_df['clients.unique_identifier'].sum()\n",
    "\n",
    "        active_clients_by_proj_type_df['Reporting Month'] = REPORT_START_DATE.strftime(\"%b-%Y\")\n",
    "        active_clients_by_proj_type_df['Reporting Window'] = time_range\n",
    "        \n",
    "        list_of_dfs_3.append(active_clients_by_proj_type_df)\n",
    "    REPORT_START_DATE = REPORT_START_DATE + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat(list_of_dfs_3).rename(columns={'clients.unique_identifier':'Active Clients Count'})\n",
    "df3.to_csv(f'{PATH}/newsletter_active_counts_by_proj_type_by_race.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for Housed Situations Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "permanent_sit = [\n",
    "        'Staying or living with family, permanent tenure', \n",
    "        'Staying or living with friends, permanent tenure', \n",
    "        'Rental by client, no ongoing housing subsidy',\n",
    "        'Rental by client, with VASH housing subsidy',\n",
    "        'Rental by client, with other ongoing housing subsidy', \n",
    "        'Permanent housing (other than RRH) for formerly homeless persons'\n",
    "        ]\n",
    "\n",
    "# A function to identify whether an enrollment had an exit or a move-in\n",
    "def exit_or_move_in(row):\n",
    "    if not pd.isnull(row['household_move_in_date.move_in_date']) and row['household_move_in_date.move_in_date']>=rep_period_start and row['household_move_in_date.move_in_date']<=rep_period_end:\n",
    "        return \"Move In to PH\"\n",
    "    else:\n",
    "        if not pd.isnull(row['enrollments.end_date']) and row['enrollments.end_date']>=rep_period_start and row['enrollments.end_date']<=rep_period_end:\n",
    "            return f\"{row['last_screen.exit_destination_text']}\"\n",
    "\n",
    "# A function to group the positive exit destination categories\n",
    "def ph_category1(row):\n",
    "    moved_in_with_family = [\n",
    "        'Staying or living with family, permanent tenure', \n",
    "        'Staying or living with friends, permanent tenure'\n",
    "        ]\n",
    "    rental_by_client = [\n",
    "        'Rental by client, no ongoing housing subsidy',\n",
    "        'Rental by client, with VASH housing subsidy',\n",
    "        'Rental by client, with other ongoing housing subsidy',\n",
    "        'Rental by client in a public housing unit',\n",
    "        'Rental by client, with HCV voucher (tenant or project based)',\n",
    "        'Rental by client, with RRH or equivalent subsidy',\n",
    "        'Rental by client, with GPD TIP housing subsidy'\n",
    "        ]\n",
    "    permanent_housing = [\n",
    "        'Permanent housing (other than RRH) for formerly homeless persons', \n",
    "        'Moved from one HOPWA funded project to HOPWA PH'\n",
    "        ]\n",
    "    owned_by_client = [\n",
    "        'Owned by client, no ongoing housing subsidy',\n",
    "        'Owned by client, with ongoing housing subsidy'\n",
    "    ]\n",
    "\n",
    "    if row['exit_dest_or_move_in']=='Move In to PH':\n",
    "        return 'Move In to PH'\n",
    "    elif row['exit_dest_or_move_in'] in moved_in_with_family:\n",
    "        return 'Moved in with Family'\n",
    "    elif row['exit_dest_or_move_in'] in rental_by_client:\n",
    "        return 'Rental by Client'\n",
    "    elif row['exit_dest_or_move_in'] in permanent_housing:\n",
    "        return 'Other Permanent Housing'\n",
    "    elif row['exit_dest_or_move_in'] in owned_by_client:\n",
    "        return 'Owned by Client'\n",
    "    else:\n",
    "        return f\"CHECK -- {row['exit_dest_or_move_in']}\"\n",
    "\n",
    "temp = df.copy()\n",
    "\n",
    "monthly_time_periods_d = {\n",
    "    \"Monthly\": 1,\n",
    "    \"Quarterly\": 4,\n",
    "    \"6 - Month\": 6,\n",
    "    \"Annual\": 12\n",
    "} \n",
    "\n",
    "list_of_dfs_4 = []\n",
    "\n",
    "REPORT_START_DATE = pd.to_datetime('2022-09-01')\n",
    "while REPORT_START_DATE<pd.to_datetime(date.today().strftime(\"%Y-%m-01\")):\n",
    "    for time_range in monthly_time_periods_d:\n",
    "        if time_range==\"Monthly\":\n",
    "            \n",
    "            # Set repording period start and end\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=1)\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=1)\n",
    "            lookback_end = rep_period_start\n",
    "    \n",
    "        else:\n",
    "            rep_period_start = pd.to_datetime(REPORT_START_DATE) - relativedelta(months=monthly_time_periods_d[time_range]-1)\n",
    "            rep_period_end = rep_period_start + relativedelta(months=monthly_time_periods_d[time_range])\n",
    "\n",
    "            # Set a lookback period\n",
    "            lookback_start = rep_period_start - relativedelta(months=monthly_time_periods_d[time_range])\n",
    "            lookback_end = rep_period_start\n",
    "\n",
    "        total_exit_to_or_move_in_df = getExitToMoveInDF(temp, rep_period_start, rep_period_end)\n",
    "        total_exit_to_or_move_in_df['exit_dest_or_move_in'] = total_exit_to_or_move_in_df.apply(lambda row: exit_or_move_in(row), axis=1)\n",
    "        total_exit_to_or_move_in_df = pd.DataFrame(total_exit_to_or_move_in_df.groupby(['static_demographics.race_text','exit_dest_or_move_in'])['clients.unique_identifier'].nunique()).reset_index()\n",
    "        total_exit_to_or_move_in_df['Permanent Destination'] = total_exit_to_or_move_in_df.apply(lambda row: ph_category1(row), axis=1)\n",
    "        total_exit_to_or_move_in_df = pd.DataFrame(total_exit_to_or_move_in_df.groupby(['static_demographics.race_text', 'Permanent Destination'])['clients.unique_identifier'].sum()).reset_index()\n",
    "        total_exit_to_or_move_in_df['Permanent Destination % by Race'] = total_exit_to_or_move_in_df['clients.unique_identifier']/total_exit_to_or_move_in_df['clients.unique_identifier'].sum()\n",
    "\n",
    "        total_exit_to_or_move_in_df['Reporting Month'] = REPORT_START_DATE.strftime(\"%b-%Y\")\n",
    "        total_exit_to_or_move_in_df['Reporting Window'] = time_range\n",
    "\n",
    "        list_of_dfs_4.append(total_exit_to_or_move_in_df)\n",
    "        \n",
    "    REPORT_START_DATE = REPORT_START_DATE + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat(list_of_dfs_4)\n",
    "df4.to_csv(f'{PATH}/newsletter_housed_counts_by_destination_by_race.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTH Racial Equity Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_race_variable(row, race):\n",
    "    if row['static_demographics.race_text']==race:\n",
    "        return race\n",
    "    else:\n",
    "        return f'Non-{race}'\n",
    "\n",
    "fth_binary_race_data_d = {}\n",
    "df1 = df.copy()\n",
    "# df1['Binary Race Variable'] = df1.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "\n",
    "rep_period_start = pd.to_datetime('2020-01-01')\n",
    "rep_period_end = rep_period_start + relativedelta(months=12)\n",
    "while rep_period_start<pd.to_datetime('2023-01-01'):\n",
    "    temp = df1.copy()\n",
    "    proj_type_list = temp['programs.project_type_code'].unique()\n",
    "    race_list = temp['static_demographics.race_text'].unique()\n",
    "    fth_binary_race_data_d[rep_period_start.strftime('%Y')] = {}\n",
    "    for race in race_list:\n",
    "        if race in ['White', 'Black, African American, or African', 'Native Hawaiian or Pacific Islander', 'Multi-Racial', 'American Indian, Alaska Native, or Indigenous', 'Asian or Asian American']:\n",
    "            temp = df1.copy()\n",
    "            temp['Binary Race Variable'] = temp.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "            temp = pd.DataFrame(getFirstTimeHomelessDF(temp, rep_period_start, rep_period_end).groupby(['Binary Race Variable','programs.project_type_code'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"FTH Count\"}).reset_index()\n",
    "            temp = pd.DataFrame(temp.pivot(index='Binary Race Variable', columns='programs.project_type_code', values='FTH Count')).reset_index()\n",
    "            temp[[x for x in temp.columns if x in proj_type_list]] = temp[[x for x in temp.columns if x in proj_type_list]].fillna(0).astype(int)\n",
    "            temp['Year'] = rep_period_start.strftime('%Y')\n",
    "            fth_binary_race_data_d[rep_period_start.strftime('%Y')][race] = temp.copy()\n",
    "\n",
    "    # Set repording period start and end\n",
    "    rep_period_start = rep_period_end\n",
    "    rep_period_end = rep_period_start + relativedelta(months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_binary_race_data_df = pd.DataFrame()\n",
    "for key in fth_binary_race_data_d:\n",
    "    for k in fth_binary_race_data_d[key]:\n",
    "        if fth_binary_race_data_df.empty:\n",
    "            fth_binary_race_data_df = fth_binary_race_data_d[key][k]\n",
    "        else:\n",
    "            fth_binary_race_data_df = pd.concat([fth_binary_race_data_df, fth_binary_race_data_d[key][k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_binary_race_data_df[fth_binary_race_data_df.columns[1:]] = fth_binary_race_data_df[fth_binary_race_data_df.columns[1:]].fillna(0).astype(int)\n",
    "fth_binary_race_data_df = fth_binary_race_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_binary_race_data_df.to_csv(f'{PATH}/binary_race_data_counts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_d = {}\n",
    "\n",
    "population_percent = {\n",
    "    \"White\":.746,\n",
    "    \"Black, African American, or African\":.056,\n",
    "    'American Indian, Alaska Native, or Indigenous':.014,\n",
    "    'Asian or Asian American':.129,\n",
    "    'Native Hawaiian or Pacific Islander':0.006,\n",
    "    'Multi-Racial':.049\n",
    "    }\n",
    "for year in fth_binary_race_data_d:\n",
    "    fth_d[year] = {}\n",
    "    for race in fth_binary_race_data_d[year]:\n",
    "        if race in population_percent: \n",
    "            fth_d[year][race] = {}\n",
    "            for col in [x for x in fth_binary_race_data_d[year][race].columns if x in proj_type_list]:\n",
    "                fth_d[year][race][col] = {}\n",
    "                for var in fth_binary_race_data_d[year][race]['Binary Race Variable'].unique():\n",
    "                    if var==race:\n",
    "                        fth_d[year][race][col][var] = (fth_binary_race_data_d[year][race][fth_binary_race_data_d[year][race]['Binary Race Variable']==race][col].values[0]/(population_percent[race]*3298634))*10000\n",
    "                    else:\n",
    "                        fth_d[year][race][col][var] = (fth_binary_race_data_d[year][race][fth_binary_race_data_d[year][race]['Binary Race Variable']!=race][col].values[0]/((1-population_percent[race])*3298634))*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_race_data_df = pd.DataFrame()\n",
    "for year in fth_d:\n",
    "    for race in fth_d[year]:\n",
    "        temp_df = pd.DataFrame(fth_d[year][race])\n",
    "        temp_df['Year'] = year\n",
    "        if fth_race_data_df.empty:\n",
    "            fth_race_data_df = temp_df.copy()\n",
    "        else:\n",
    "            fth_race_data_df = pd.concat([fth_race_data_df, temp_df])\n",
    "            \n",
    "fth_race_data_df = fth_race_data_df.reset_index()\n",
    "fth_race_data_df = fth_race_data_df.rename(columns={'index':'Binary Race Variable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_race_data_df.to_csv(f'{PATH}/binary_race_data_percent_by_pop_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_likely_d = {}\n",
    "for year in fth_d:\n",
    "    fth_likely_d[year] = {}\n",
    "    for race in fth_d[year]:\n",
    "        fth_likely_d[year][race] = {}\n",
    "        for key in fth_d[year][race]:\n",
    "            if fth_d[year][race][key][f'Non-{race}']!=0:\n",
    "                fth_likely_d[year][race][key] = fth_d[year][race][key][race]/fth_d[year][race][key][f'Non-{race}']\n",
    "            else:\n",
    "                fth_likely_d[year][race][key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_likely_data_df = pd.DataFrame()\n",
    "for year in fth_likely_d:\n",
    "    temp_df = pd.DataFrame(fth_likely_d[year]).T\n",
    "    temp_df['Year'] = year\n",
    "    if fth_likely_data_df.empty:\n",
    "        fth_likely_data_df = temp_df.copy()\n",
    "    else:\n",
    "        fth_likely_data_df = pd.concat([fth_likely_data_df, temp_df])\n",
    "\n",
    "fth_likely_data_df = fth_likely_data_df.reset_index().rename(columns={'index':'Binary Race Variable'})\n",
    "fth_likely_data_df[fth_likely_data_df.columns[1:]] = fth_likely_data_df[fth_likely_data_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth_likely_data_df.to_csv(f'{PATH}/binary_race_likeliness_data_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Racial Equity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_race_variable(row, race):\n",
    "    if row['static_demographics.race_text']==race:\n",
    "        return race\n",
    "    else:\n",
    "        return f'Non-{race}'\n",
    "\n",
    "active_binary_race_data_d = {}\n",
    "df1 = df.copy()\n",
    "# df1['Binary Race Variable'] = df1.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "\n",
    "rep_period_start = pd.to_datetime('2020-01-01')\n",
    "rep_period_end = rep_period_start + relativedelta(months=12)\n",
    "while rep_period_start<pd.to_datetime('2023-01-01'):\n",
    "    temp = df1.copy()\n",
    "    proj_type_list = temp['programs.project_type_code'].unique()\n",
    "    race_list = temp['static_demographics.race_text'].unique()\n",
    "    active_binary_race_data_d[rep_period_start.strftime('%Y')] = {}\n",
    "    for race in race_list:\n",
    "        if race in ['White', 'Black, African American, or African', 'Native Hawaiian or Pacific Islander', 'Multi-Racial', 'American Indian, Alaska Native, or Indigenous', 'Asian or Asian American']:\n",
    "            temp = df1.copy()\n",
    "            temp['Binary Race Variable'] = temp.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "            temp = pd.DataFrame(getActiveClientsDF(temp, rep_period_start, rep_period_end).groupby(['Binary Race Variable','programs.project_type_code'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"Active Count\"}).reset_index()\n",
    "            temp = pd.DataFrame(temp.pivot(index='Binary Race Variable', columns='programs.project_type_code', values='Active Count')).reset_index()\n",
    "            temp[[x for x in temp.columns if x in proj_type_list]] = temp[[x for x in temp.columns if x in proj_type_list]].fillna(0).astype(int)\n",
    "            temp['Year'] = rep_period_start.strftime('%Y')\n",
    "            active_binary_race_data_d[rep_period_start.strftime('%Y')][race] = temp.copy()\n",
    "\n",
    "    # Set repording period start and end\n",
    "    rep_period_start = rep_period_end\n",
    "    rep_period_end = rep_period_start + relativedelta(months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_binary_race_data_df = pd.DataFrame()\n",
    "for key in active_binary_race_data_d:\n",
    "    for k in active_binary_race_data_d[key]:\n",
    "        if active_binary_race_data_df.empty:\n",
    "            active_binary_race_data_df = active_binary_race_data_d[key][k]\n",
    "        else:\n",
    "            active_binary_race_data_df = pd.concat([active_binary_race_data_df, active_binary_race_data_d[key][k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_binary_race_data_df[active_binary_race_data_df.columns[1:]] = active_binary_race_data_df[active_binary_race_data_df.columns[1:]].fillna(0).astype(int)\n",
    "active_binary_race_data_df = active_binary_race_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_binary_race_data_df.to_csv(f'{PATH}/active_binary_race_data_counts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_d = {}\n",
    "\n",
    "population_percent = {\n",
    "    \"White\":.746,\n",
    "    \"Black, African American, or African\":.056,\n",
    "    'American Indian, Alaska Native, or Indigenous':.014,\n",
    "    'Asian or Asian American':.129,\n",
    "    'Native Hawaiian or Pacific Islander':0.006,\n",
    "    'Multi-Racial':.049\n",
    "    }\n",
    "for year in active_binary_race_data_d:\n",
    "    active_d[year] = {}\n",
    "    for race in active_binary_race_data_d[year]:\n",
    "        if race in population_percent: \n",
    "            active_d[year][race] = {}\n",
    "            for col in [x for x in active_binary_race_data_d[year][race].columns if x in proj_type_list]:\n",
    "                active_d[year][race][col] = {}\n",
    "                for var in active_binary_race_data_d[year][race]['Binary Race Variable'].unique():\n",
    "                    if var==race:\n",
    "                        active_d[year][race][col][var] = (active_binary_race_data_d[year][race][active_binary_race_data_d[year][race]['Binary Race Variable']==race][col].values[0]/(population_percent[race]*3298634))*10000\n",
    "                    else:\n",
    "                        active_d[year][race][col][var] = (active_binary_race_data_d[year][race][active_binary_race_data_d[year][race]['Binary Race Variable']!=race][col].values[0]/((1-population_percent[race])*3298634))*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_race_data_df = pd.DataFrame()\n",
    "for year in active_d:\n",
    "    for race in active_d[year]:\n",
    "        temp_df = pd.DataFrame(active_d[year][race])\n",
    "        temp_df['Year'] = year\n",
    "        if active_race_data_df.empty:\n",
    "            active_race_data_df = temp_df.copy()\n",
    "        else:\n",
    "            active_race_data_df = pd.concat([active_race_data_df, temp_df])\n",
    "            \n",
    "active_race_data_df = active_race_data_df.reset_index()\n",
    "active_race_data_df = active_race_data_df.rename(columns={'index':'Binary Race Variable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_race_data_df.to_csv(f'{PATH}/active_binary_race_data_percent_by_pop_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_likely_d = {}\n",
    "for year in active_d:\n",
    "    active_likely_d[year] = {}\n",
    "    for race in active_d[year]:\n",
    "        active_likely_d[year][race] = {}\n",
    "        for key in active_d[year][race]:\n",
    "            if active_d[year][race][key][f'Non-{race}']!=0:\n",
    "                active_likely_d[year][race][key] = active_d[year][race][key][race]/active_d[year][race][key][f'Non-{race}']\n",
    "            else:\n",
    "                active_likely_d[year][race][key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_likely_data_df = pd.DataFrame()\n",
    "for year in active_likely_d:\n",
    "    temp_df = pd.DataFrame(active_likely_d[year]).T\n",
    "    temp_df['Year'] = year\n",
    "    if active_likely_data_df.empty:\n",
    "        active_likely_data_df = temp_df.copy()\n",
    "    else:\n",
    "        active_likely_data_df = pd.concat([active_likely_data_df, temp_df])\n",
    "\n",
    "active_likely_data_df = active_likely_data_df.reset_index().rename(columns={'index':'Binary Race Variable'})\n",
    "active_likely_data_df[active_likely_data_df.columns[1:]] = active_likely_data_df[active_likely_data_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_likely_data_df.to_csv(f'{PATH}/active_binary_race_likeliness_data_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housed Racial Equity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_race_variable(row, race):\n",
    "    if row['static_demographics.race_text']==race:\n",
    "        return race\n",
    "    else:\n",
    "        return f'Non-{race}'\n",
    "\n",
    "housed_binary_race_data_d = {}\n",
    "df1 = df.copy()\n",
    "# df1['Binary Race Variable'] = df1.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "\n",
    "rep_period_start = pd.to_datetime('2020-01-01')\n",
    "rep_period_end = rep_period_start + relativedelta(months=12)\n",
    "while rep_period_start<pd.to_datetime('2023-01-01'):\n",
    "    temp = df1.copy()\n",
    "    proj_type_list = temp['programs.project_type_code'].unique()\n",
    "    race_list = temp['static_demographics.race_text'].unique()\n",
    "    housed_binary_race_data_d[rep_period_start.strftime('%Y')] = {}\n",
    "    for race in race_list:\n",
    "        if race in ['White', 'Black, African American, or African', 'Native Hawaiian or Pacific Islander', 'Multi-Racial', 'American Indian, Alaska Native, or Indigenous', 'Asian or Asian American']:\n",
    "            temp = df1.copy()\n",
    "            temp['Binary Race Variable'] = temp.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "            temp = pd.DataFrame(getClientsExitedAndHoused(temp, rep_period_start, rep_period_end).groupby(['Binary Race Variable','programs.project_type_code'])['clients.unique_identifier'].nunique().sort_values(ascending=False)).rename(columns={\"clients.unique_identifier\": \"housed Count\"}).reset_index()\n",
    "            temp = pd.DataFrame(temp.pivot(index='Binary Race Variable', columns='programs.project_type_code', values='housed Count')).reset_index()\n",
    "            temp[[x for x in temp.columns if x in proj_type_list]] = temp[[x for x in temp.columns if x in proj_type_list]].fillna(0).astype(int)\n",
    "            temp['Year'] = rep_period_start.strftime('%Y')\n",
    "            housed_binary_race_data_d[rep_period_start.strftime('%Y')][race] = temp.copy()\n",
    "\n",
    "    # Set repording period start and end\n",
    "    rep_period_start = rep_period_end\n",
    "    rep_period_end = rep_period_start + relativedelta(months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_binary_race_data_df = pd.DataFrame()\n",
    "for key in housed_binary_race_data_d:\n",
    "    for k in housed_binary_race_data_d[key]:\n",
    "        if housed_binary_race_data_df.empty:\n",
    "            housed_binary_race_data_df = housed_binary_race_data_d[key][k]\n",
    "        else:\n",
    "            housed_binary_race_data_df = pd.concat([housed_binary_race_data_df, housed_binary_race_data_d[key][k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_binary_race_data_df[housed_binary_race_data_df.columns[1:]] = housed_binary_race_data_df[housed_binary_race_data_df.columns[1:]].fillna(0).astype(int)\n",
    "housed_binary_race_data_df = housed_binary_race_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_binary_race_data_df.to_csv(f'{PATH}/housed_binary_race_data_counts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_d = {}\n",
    "\n",
    "population_percent = {\n",
    "    \"White\":.746,\n",
    "    \"Black, African American, or African\":.056,\n",
    "    'American Indian, Alaska Native, or Indigenous':.014,\n",
    "    'Asian or Asian American':.129,\n",
    "    'Native Hawaiian or Pacific Islander':0.006,\n",
    "    'Multi-Racial':.049\n",
    "    }\n",
    "for year in housed_binary_race_data_d:\n",
    "    housed_d[year] = {}\n",
    "    for race in housed_binary_race_data_d[year]:\n",
    "        if race in population_percent: \n",
    "            housed_d[year][race] = {}\n",
    "            for col in [x for x in housed_binary_race_data_d[year][race].columns if x in proj_type_list]:\n",
    "                housed_d[year][race][col] = {}\n",
    "                for var in housed_binary_race_data_d[year][race]['Binary Race Variable'].unique():\n",
    "                    if var==race:\n",
    "                        housed_d[year][race][col][var] = (housed_binary_race_data_d[year][race][housed_binary_race_data_d[year][race]['Binary Race Variable']==race][col].values[0]/(population_percent[race]*3298634))*10000\n",
    "                    else:\n",
    "                        housed_d[year][race][col][var] = (housed_binary_race_data_d[year][race][housed_binary_race_data_d[year][race]['Binary Race Variable']!=race][col].values[0]/((1-population_percent[race])*3298634))*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_race_data_df = pd.DataFrame()\n",
    "for year in housed_d:\n",
    "    for race in housed_d[year]:\n",
    "        temp_df = pd.DataFrame(housed_d[year][race])\n",
    "        temp_df['Year'] = year\n",
    "        if housed_race_data_df.empty:\n",
    "            housed_race_data_df = temp_df.copy()\n",
    "        else:\n",
    "            housed_race_data_df = pd.concat([housed_race_data_df, temp_df])\n",
    "            \n",
    "housed_race_data_df = housed_race_data_df.reset_index()\n",
    "housed_race_data_df = housed_race_data_df.rename(columns={'index':'Binary Race Variable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_race_data_df.to_csv(f'{PATH}/housed_binary_race_data_percent_by_pop_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_likely_d = {}\n",
    "for year in housed_d:\n",
    "    housed_likely_d[year] = {}\n",
    "    for race in housed_d[year]:\n",
    "        housed_likely_d[year][race] = {}\n",
    "        for key in housed_d[year][race]:\n",
    "            if housed_d[year][race][key][f'Non-{race}']!=0:\n",
    "                housed_likely_d[year][race][key] = housed_d[year][race][key][race]/housed_d[year][race][key][f'Non-{race}']\n",
    "            else:\n",
    "                housed_likely_d[year][race][key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_likely_data_df = pd.DataFrame()\n",
    "for year in housed_likely_d:\n",
    "    temp_df = pd.DataFrame(housed_likely_d[year]).T\n",
    "    temp_df['Year'] = year\n",
    "    if housed_likely_data_df.empty:\n",
    "        housed_likely_data_df = temp_df.copy()\n",
    "    else:\n",
    "        housed_likely_data_df = pd.concat([housed_likely_data_df, temp_df])\n",
    "\n",
    "housed_likely_data_df = housed_likely_data_df.reset_index().rename(columns={'index':'Binary Race Variable'})\n",
    "housed_likely_data_df[housed_likely_data_df.columns[1:]] = housed_likely_data_df[housed_likely_data_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "housed_likely_data_df.to_csv(f'{PATH}/housed_binary_race_likeliness_data_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('assets/PIT Data.xlsx')\n",
    "pit_data_d = {}\n",
    "\n",
    "for sheet in xls.sheet_names:\n",
    "    pit_data_d[sheet.split(' ')[0]] = pd.read_excel(xls, sheet)\n",
    "    pit_data_d[sheet.split(' ')[0]][pit_data_d[sheet.split(' ')[0]].columns[1:]] = pit_data_d[sheet.split(' ')[0]][pit_data_d[sheet.split(' ')[0]].columns[1:]].fillna(0).astype(int)\n",
    "    pit_data_d[sheet.split(' ')[0]]['Sheltered'] = pit_data_d[sheet.split(' ')[0]]['Emergency'] + pit_data_d[sheet.split(' ')[0]]['Transitional'] + pit_data_d[sheet.split(' ')[0]]['Safe Haven']\n",
    "    pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]][['Unnamed: 0', 'Sheltered', 'Unsheltered', 'Total']]\n",
    "    pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]].T\n",
    "    pit_data_d[sheet.split(' ')[0]].columns = pit_data_d[sheet.split(' ')[0]].iloc[0, :]\n",
    "    pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]][1:]\n",
    "    pit_data_d[sheet.split(' ')[0]].columns = [x.replace('\\n', '') for x in pit_data_d[sheet.split(' ')[0]].columns]\n",
    "    pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]].iloc[:,-6:]\n",
    "    if sheet.split(' ')[0] in ['2020', '2021']:\n",
    "        pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]].rename(columns=\n",
    "                                                                                 {'American Indian or Alaska Native':'American Indian, Alaska Native, or Indigenous',\n",
    "                                                                                  'Asian':'Asian or Asian American',\n",
    "                                                                                  'Black or African-American':'Black, African American, or African',\n",
    "                                                                                  'Native Hawaiian or Other Pacific Islander':'Native Hawaiian or Pacific Islander',\n",
    "                                                                                  })\n",
    "    pit_data_d[sheet.split(' ')[0]] = pit_data_d[sheet.split(' ')[0]].T.reset_index().rename(columns={'index':'static_demographics.race_text'})\n",
    "    pit_data_d[sheet.split(' ')[0]]['Year'] = int(sheet.split(' ')[0])\n",
    "\n",
    "pit_data_df = pd.DataFrame()\n",
    "for key in pit_data_d:\n",
    "    if pit_data_df.empty:\n",
    "        pit_data_df = pit_data_d[key]\n",
    "    else:\n",
    "        pit_data_df = pd.concat([pit_data_df, pit_data_d[key]])\n",
    "pit_data_df = pit_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pit_data_d = {}\n",
    "for key in pit_data_d:\n",
    "    binary_pit_data_d[key] = {}\n",
    "    for race in pit_data_d[key]['static_demographics.race_text'].unique():\n",
    "        temp = pit_data_d[key].copy()\n",
    "        temp['Binary Race Variable'] = temp.apply(lambda row: binary_race_variable(row, race), axis=1)\n",
    "        temp = pd.merge(pd.DataFrame(temp.groupby('Binary Race Variable')['Sheltered'].sum()).reset_index(), pd.DataFrame(temp.groupby('Binary Race Variable')['Unsheltered'].sum()).reset_index(), on='Binary Race Variable', how='left')\n",
    "        temp['Year'] = int(key)\n",
    "        binary_pit_data_d[key][race] = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pit_data_df = pd.DataFrame()\n",
    "\n",
    "for year in binary_pit_data_d:\n",
    "    for race in binary_pit_data_d[year]:\n",
    "        if binary_pit_data_df.empty:\n",
    "            binary_pit_data_df = binary_pit_data_d[year][race].copy()\n",
    "        else:\n",
    "            binary_pit_data_df = pd.concat([binary_pit_data_df, binary_pit_data_d[year][race].copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pit_data_df.to_csv(f'{PATH}/binary_pit_data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pit_data_d = {}\n",
    "\n",
    "population_percent = {\n",
    "    \"White\":.746,\n",
    "    \"Black, African American, or African\":.056,\n",
    "    'American Indian, Alaska Native, or Indigenous':.014,\n",
    "    'Asian or Asian American':.129,\n",
    "    'Native Hawaiian or Pacific Islander':0.006,\n",
    "    'Multi-Racial':.049\n",
    "    }\n",
    "for year in binary_pit_data_d:\n",
    "    calc_pit_data_d[year] = {}\n",
    "    for race in binary_pit_data_d[year]:\n",
    "        if race in population_percent: \n",
    "            calc_pit_data_d[year][race] = {}\n",
    "            for col in [x for x in binary_pit_data_d[year][race].columns if x in ['Sheltered', 'Unsheltered']]:\n",
    "                calc_pit_data_d[year][race][col] = {}\n",
    "                for var in binary_pit_data_d[year][race]['Binary Race Variable'].unique():\n",
    "                    if var==race:\n",
    "                        calc_pit_data_d[year][race][col][var] = (binary_pit_data_d[year][race][binary_pit_data_d[year][race]['Binary Race Variable']==race][col].values[0]/(population_percent[race]*3298634))*10000\n",
    "                    else:\n",
    "                        calc_pit_data_d[year][race][col][var] = (binary_pit_data_d[year][race][binary_pit_data_d[year][race]['Binary Race Variable']!=race][col].values[0]/((1-population_percent[race])*3298634))*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pit_data_df = pd.DataFrame()\n",
    "\n",
    "for year in calc_pit_data_d:\n",
    "    for race in calc_pit_data_d[year]:\n",
    "        temp = pd.DataFrame(calc_pit_data_d[year][race])\n",
    "        temp['Year'] = int(year)\n",
    "        if calc_pit_data_df.empty:\n",
    "            calc_pit_data_df = temp.copy()\n",
    "        else:\n",
    "            calc_pit_data_df = pd.concat([calc_pit_data_df, temp.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pit_data_df.to_csv(f'{PATH}/calc_pit_data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_data_likely_d = {}\n",
    "for year in calc_pit_data_d:\n",
    "    pit_data_likely_d[year] = {}\n",
    "    for race in calc_pit_data_d[year]:\n",
    "        pit_data_likely_d[year][race] = {}\n",
    "        for key in calc_pit_data_d[year][race]:\n",
    "            if calc_pit_data_d[year][race][key][f'Non-{race}']!=0:\n",
    "                pit_data_likely_d[year][race][key] = calc_pit_data_d[year][race][key][race]/calc_pit_data_d[year][race][key][f'Non-{race}']\n",
    "            else:\n",
    "                pit_data_likely_d[year][race][key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_data_likely_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for year in pit_data_likely_d:\n",
    "    for race in pit_data_likely_d[year]:\n",
    "        temp = pd.DataFrame(pd.Series(pit_data_likely_d[year][race]))\n",
    "        temp = temp.rename(columns={0:'Likely Metric'})\n",
    "        temp['Year'] = int(year)\n",
    "        temp['Race'] = race\n",
    "        if pit_data_likely_df.empty:\n",
    "            pit_data_likely_df = temp.copy()\n",
    "        else:\n",
    "            pit_data_likely_df = pd.concat([pit_data_likely_df, temp.copy()])\n",
    "pit_data_likely_df = pit_data_likely_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_data_likely_df.to_csv(f'{PATH}/pit_data_likely_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_data_df.to_csv(f'{PATH}/pit_data_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
